{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the load_dotenv function to access environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "# The override=True ensures existing variables are updated if needed\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os module to access environment variables\n",
    "import os\n",
    "\n",
    "# Retrieve the OpenAI API key from environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check if the API key is set and provide feedback\n",
    "if openai_api_key:\n",
    "    # Display only the first 8 characters of the key for security\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenAI client library for interacting with the OpenAI API\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client to enable API interactions\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a question using the OpenAI API\n",
    "def question_agent(prompt):\n",
    "    \"\"\"\n",
    "    Sends a prompt to the OpenAI API and returns the generated response.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input prompt to send to the model.\n",
    "    \n",
    "    Returns:\n",
    "        str: The response content from the model.\n",
    "    \"\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Specify the model to use\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]  # Format the prompt as a user message\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fun space-related question using the question_agent function\n",
    "question = question_agent(\"Ask me a fun question about space?\")\n",
    "\n",
    "# Print the generated question\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a response to a given question using the OpenAI API\n",
    "def reply_agent(question):\n",
    "    \"\"\"\n",
    "    Sends a question to the OpenAI API and returns the generated response.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The question to send to the model.\n",
    "    \n",
    "    Returns:\n",
    "        str: The response content from the model.\n",
    "    \"\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Specify the model to use\n",
    "        messages=[{\"role\": \"user\", \"content\": question}]  # Format the question as a user message\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Use the reply_agent function to answer the previously generated question\n",
    "answer = reply_agent(question)\n",
    "\n",
    "# Print the answer\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The installation command is commented out as it's typically run in a terminal\n",
    "# pip install openai-agents\n",
    "\n",
    "# Import core components from the openai-agents library\n",
    "from agents import Agent, Runner, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversational AI agent with a friendly personality\n",
    "agent = Agent(\n",
    "    name=\"Friendly Assistant\",\n",
    "    instructions=\"You are a helpful and friendly assistant who loves to help people learn new things.\",\n",
    "    model=\"gpt-4o-mini\"  # Specify the model to use\n",
    ")\n",
    "\n",
    "# Print the agent object to inspect its configuration\n",
    "print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the trace function for logging (already imported in previous cell)\n",
    "from agents import Runner, trace\n",
    "\n",
    "# Run the agent with a prompt to explain AI agents in simple terms\n",
    "with trace(\"First Agent Conversation\"):\n",
    "    result = await Runner.run(agent, \"Explain what an AI agent is in simple terms\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two agents with distinct personalities\n",
    "comedy_agent = Agent(\n",
    "    name=\"Comedy Bot\",\n",
    "    instructions=\"You are a comedian who explains everything through jokes and humor. Make learning fun!\",\n",
    "    model=\"gpt-4o-mini\"  # Specify the model to use\n",
    ")\n",
    "\n",
    "serious_agent = Agent(\n",
    "    name=\"Professor\",\n",
    "    instructions=\"You are a serious academic professor who gives detailed, scholarly explanations.\",\n",
    "    model=\"gpt-4o-mini\"  # Specify the model to use\n",
    ")\n",
    "\n",
    "# Define a common question to test both agents\n",
    "question = \"What is machine learning?\"\n",
    "\n",
    "# Run both agents with the same question and compare their responses\n",
    "with trace(\"Personality Comparison\"):\n",
    "    # Run the comedy agent\n",
    "    comedy_result = await Runner.run(comedy_agent, question)\n",
    "    print(\"ðŸŽ­ COMEDY AGENT:\")\n",
    "    print(comedy_result.final_output)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Run the serious agent\n",
    "    serious_result = await Runner.run(serious_agent, question)\n",
    "    print(\"ðŸŽ“ PROFESSOR AGENT:\")\n",
    "    print(serious_result.final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
